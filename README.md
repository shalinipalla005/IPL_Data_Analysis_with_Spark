# ğŸ IPL Data Analysis with PySpark

### ğŸ“Š Project Overview

This project explores and analyzes detailed IPL (Indian Premier League) cricket match data using **PySpark**. It processes large-scale, ball-by-ball datasets and extracts key insights about team performance, player impact, toss outcomes, and bowling economy across different seasons.

Designed for scalability and performance, this project uses Sparkâ€™s distributed processing power to efficiently handle and analyze structured data.

---

### ğŸ› ï¸ Technologies Used

* **Apache Spark (PySpark)**
* **Google Colab / Databricks**
* **Pandas** and **Seaborn** for visualization
* **Matplotlib** for plotting
* **CSV** as data source

---

### ğŸ“ Datasets Used

The project uses the following IPL CSV datasets:

| File               | Description                                |
| ------------------ | ------------------------------------------ |
| `Ball_By_Ball.csv` | Ball-wise match data                       |
| `Match.csv`        | Match metadata including results and venue |
| `Player.csv`       | Player information                         |
| `Player_Match.csv` | Player performance per match               |
| `Team.csv`         | Team metadata                              |

---

### ğŸ“Œ Key Features

#### ğŸ” Exploratory Data Analysis (EDA)

* Number of matches played per season
* Venue-wise match distribution
* Impact of toss on match outcomes
* Winning margin and outcome breakdowns

#### ğŸ§® Statistical Aggregations

* Economy rate of bowlers per season
* Total and average runs per innings
* High-impact deliveries (runs > 6 or wicket)
* Top run scorers per match or season

#### ğŸ“Š Visualizations

* Count plots for toss vs match result
* Bar plots for runs, wickets, and top performers
* Season-wise trends using line and bar charts

---

### ğŸš€ How to Run

#### ğŸ“ Option 1: Google Colab

1. Open the notebook in Colab
2. Install PySpark using:

   ```python
   !pip install pyspark
   ```
3. Upload your datasets to the Colab session
4. Run all cells to reproduce the analysis

---

### ğŸ“‚ Project Structure

```
ipl-data-analysis/
â”œâ”€â”€ ipl_data_analysis_spark.ipynb  # Main notebook
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Ball_By_Ball.csv
â”‚   â”œâ”€â”€ Match.csv
â”‚   â”œâ”€â”€ Player.csv
â”‚   â”œâ”€â”€ Player_Match.csv
â”‚   â””â”€â”€ Team.csv
â””â”€â”€ README.md                      # This file
```

---

### ğŸ§  Skills Demonstrated

* Data Cleaning & Preprocessing with PySpark
* Complex GroupBy and Window Functions
* DataFrame joins and schema definition
* Exploratory Data Analysis (EDA)
* Data Visualization with Seaborn/Matplotlib
* Working in distributed environments (Colab / Databricks)

---
